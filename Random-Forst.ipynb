{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "DATA_PATH = './data/'\n",
    "dataset = 'adult'\n",
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load adult\n",
    "# https://towardsdatascience.com/logistic-regression-classifier-on-census-income-data-e1dbef0b5738\n",
    "def load_adult():\n",
    "    columns = [\"age\",\n",
    "               \"workClass\", \n",
    "               \"fnlwgt\", \n",
    "               \"education\", \n",
    "               \"education-num\",\n",
    "               \"marital-status\", \n",
    "               \"occupation\", \n",
    "               \"relationship\",\n",
    "               \"race\", \n",
    "               \"sex\", \n",
    "               \"capital-gain\", \n",
    "               \"capital-loss\",\n",
    "               \"hours-per-week\", \n",
    "               \"native-country\", \n",
    "               \"income\"]\n",
    "    \n",
    "    train = pd.read_csv(os.path.join(DATA_PATH, 'adult/data'), names=columns, sep=' *, *', na_values='?', engine='python')\n",
    "    test = pd.read_csv(os.path.join(DATA_PATH, 'adult/test'), names=columns, sep=' *, *', skiprows=1, na_values='?', engine='python')\n",
    "\n",
    "#     test['income'].replace(regex=True, inplace=True, to_replace=r'\\.', value=r'')\n",
    "#     adult = pd.concat([test,train])\n",
    "#     adult.reset_index(inplace=True, drop=True)\n",
    "#     return adult,\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_adult()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnsSelector init\n",
      "ColumnsSelector init\n",
      "CategoricalImputer init\n",
      "CategoricalEncoder init\n"
     ]
    }
   ],
   "source": [
    "class ColumnsSelector(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "    def __init__(self, type):\n",
    "        print(\"ColumnsSelector init\")\n",
    "        self.type = type\n",
    "  \n",
    "    def fit(self, X, y=None):\n",
    "        print(\"ColumnsSelector fit\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"ColumnsSelector transofrm\")\n",
    "        return X.select_dtypes(include=[self.type])\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "    def __init__(self, dropFirst=True):\n",
    "        print(\"CategoricalEncoder init\")\n",
    "        self.categories = dict()\n",
    "        self.dropFirst = dropFirst\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        print(\"CategoricalEncoder fit\")\n",
    "        join_df = pd.concat([train_data, test_data])\n",
    "        join_df = join_df.select_dtypes(include=['object'])\n",
    "        for column in join_df.columns:\n",
    "            self.categories[column] = join_df[column].value_counts().index.tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print(\"CategoricalEncoder transform\")\n",
    "        X_copy = X.copy()\n",
    "        X_copy = X_copy.select_dtypes(include=['object'])\n",
    "        for column in X_copy.columns:\n",
    "            X_copy[column] = X_copy[column].astype({column: CategoricalDtype(self.categories[column])})\n",
    "        return pd.get_dummies(X_copy, drop_first=self.dropFirst)\n",
    "\n",
    "class CategoricalImputer(BaseEstimator, TransformerMixin):\n",
    "  \n",
    "    def __init__(self, columns = None, strategy='most_frequent'):\n",
    "        print(\"CategoricalImputer init\")\n",
    "        self.columns = columns\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        print(\"CategoricalImputer fit\")\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "\n",
    "        if self.strategy is 'most_frequent':\n",
    "            self.fill = {column: X[column].value_counts().index[0] for \n",
    "            column in self.columns}\n",
    "        else:\n",
    "            self.fill = {column: '0' for column in self.columns}\n",
    "\n",
    "        return self\n",
    "      \n",
    "    def transform(self,X):\n",
    "        print(\"CategoricalImputer transform\")\n",
    "        X_copy = X.copy()\n",
    "        for column in self.columns:\n",
    "            X_copy[column] = X_copy[column].fillna(self.fill[column])\n",
    "        return X_copy\n",
    "    \n",
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"num_attr_selector\", ColumnsSelector(type='int64')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"cat_attr_selector\", ColumnsSelector(type='object')),\n",
    "    (\"cat_imputer\", CategoricalImputer(columns=['workClass','occupation', 'native-country'])),\n",
    "    (\"encoder\", CategoricalEncoder(dropFirst=True))\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion([(\"num_pipe\", num_pipeline), (\"cat_pipeline\", cat_pipeline)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_data.copy(), test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"income\"] = X_train[\"income\"].apply(lambda x: 0 if x=='<=50K' else 1)\n",
    "y_train = X_train['income']\n",
    "X_train = X_train.drop('income', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"income\"] = X_test[\"income\"].apply(lambda x:0 if x=='<=50K.' else 1)\n",
    "y_test = X_test['income']\n",
    "X_test = X_test.drop('income', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnsSelector fit\n",
      "ColumnsSelector transofrm\n",
      "ColumnsSelector fit\n",
      "ColumnsSelector transofrm\n",
      "CategoricalImputer fit\n",
      "CategoricalImputer transform\n",
      "CategoricalEncoder fit\n",
      "CategoricalEncoder transform\n",
      "ColumnsSelector fit\n",
      "ColumnsSelector transofrm\n",
      "ColumnsSelector fit\n",
      "ColumnsSelector transofrm\n",
      "CategoricalImputer fit\n",
      "CategoricalImputer transform\n",
      "CategoricalEncoder fit\n",
      "CategoricalEncoder transform\n"
     ]
    }
   ],
   "source": [
    "X_train_processed = full_pipeline.fit_transform(X_train)\n",
    "X_test_processed = full_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, \n",
    "                            criterion='gini', \n",
    "                            max_features=None,  \n",
    "                            min_samples_split=0.05, \n",
    "                            min_samples_leaf=0.001,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 844 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=None,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=0.001, min_samples_split=0.05,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "                       oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.852\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test_processed)\n",
    "acc = round(accuracy_score(y_pred, y_test.values), 3)\n",
    "print(\"accuracy_score:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_conf[:5]\n",
      " [0.99986679 0.69951466 0.81916499 0.05156428 0.99979677]\n"
     ]
    }
   ],
   "source": [
    "# confidence scores\n",
    "y_prob = rf.predict_proba(X_test_processed)\n",
    "y_conf = y_prob[:, 0]\n",
    "print(\"y_conf[:5]\\n\", y_conf[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99986679, 0.69951466, 0.81916499, ..., 0.35639908, 0.05156428,\n",
       "       0.28153947])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_map = {}\n",
    "for conf in y_conf:\n",
    "    count_map[conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pos = np.arange(len(y_pred))\n",
    " \n",
    "# # Create bars\n",
    "# plt.bar(y_pos, y_conf)\n",
    " \n",
    "# # Create names on the x-axis\n",
    "# # plt.xticks(y_pos, bars)\n",
    " \n",
    "# # Show graphic\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# filename = f'{dataset}_rf_{acc}.pkl'\n",
    "# with open(os.path.join('models', filename), 'wb') as rf_fd:\n",
    "#     pickle.dump(rf, rf_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save pipeline\n",
    "# filename = f'{dataset}_rf_{acc}_pipeline.pkl'\n",
    "# with open(os.path.join('models', filename), 'wb') as pl_fd:\n",
    "#     pickle.dump(full_pipeline, pl_fd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1]",
   "language": "python",
   "name": "conda-env-tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
